{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regression_nn_estimator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iQxhfWd2iJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "91dc2e1d-e2ea-4f94-cc2a-52fc5914d9dc"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/joberthrogers18/Machine-Learning-Training/master/deep-learning_tensorflow/Neural_Network/house_prices.csv'\n",
        "\n",
        "base = pd.read_csv(url)\n",
        "base.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>sqft_living15</th>\n",
              "      <th>sqft_lot15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7129300520</td>\n",
              "      <td>20141013T000000</td>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1180</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "      <td>1340</td>\n",
              "      <td>5650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6414100192</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2570</td>\n",
              "      <td>7242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2170</td>\n",
              "      <td>400</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>98125</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>1690</td>\n",
              "      <td>7639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5631500400</td>\n",
              "      <td>20150225T000000</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>770</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>770</td>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>98028</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>2720</td>\n",
              "      <td>8062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2487200875</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1960</td>\n",
              "      <td>5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1050</td>\n",
              "      <td>910</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>98136</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>1360</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1954400510</td>\n",
              "      <td>20150218T000000</td>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1680</td>\n",
              "      <td>8080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1680</td>\n",
              "      <td>0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>98074</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "      <td>1800</td>\n",
              "      <td>7503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id             date     price  ...     long  sqft_living15  sqft_lot15\n",
              "0  7129300520  20141013T000000  221900.0  ... -122.257           1340        5650\n",
              "1  6414100192  20141209T000000  538000.0  ... -122.319           1690        7639\n",
              "2  5631500400  20150225T000000  180000.0  ... -122.233           2720        8062\n",
              "3  2487200875  20141209T000000  604000.0  ... -122.393           1360        5000\n",
              "4  1954400510  20150218T000000  510000.0  ... -122.045           1800        7503\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRsILfBH2uBh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "173e3db4-f97a-4174-c5c2-1b5e3b051d7d"
      },
      "source": [
        "base.columns"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
              "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
              "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
              "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te5S2Qyb2xn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns_used = [ 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
        "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
        "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
        "       'lat', 'long']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpDv_4bd3Av4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "b18f239b-4748-48cb-94bf-626e73f4dcdb"
      },
      "source": [
        "# usecols is an option to define the columns desire to manipulate\n",
        "base = pd.read_csv(url, usecols=columns_used)\n",
        "base.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1180</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2570</td>\n",
              "      <td>7242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2170</td>\n",
              "      <td>400</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>98125</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>770</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>770</td>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>98028</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1960</td>\n",
              "      <td>5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1050</td>\n",
              "      <td>910</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>98136</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1680</td>\n",
              "      <td>8080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1680</td>\n",
              "      <td>0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>98074</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      price  bedrooms  bathrooms  ...  zipcode      lat     long\n",
              "0  221900.0         3       1.00  ...    98178  47.5112 -122.257\n",
              "1  538000.0         3       2.25  ...    98125  47.7210 -122.319\n",
              "2  180000.0         2       1.00  ...    98028  47.7379 -122.233\n",
              "3  604000.0         4       3.00  ...    98136  47.5208 -122.393\n",
              "4  510000.0         3       2.00  ...    98074  47.6168 -122.045\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiA53Pn13Uqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler_x = MinMaxScaler()\n",
        "\n",
        "classes_used = ['bedrooms', 'bathrooms', 'sqft_living',\n",
        "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
        "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
        "       'lat', 'long']\n",
        "\n",
        "base[classes_used] = scaler_x.fit_transform(base[classes_used])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSBSnTom4eHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "7d5b352f-3820-40d0-faf5-f2876ab2a6c9"
      },
      "source": [
        "# base with scaler\n",
        "base.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>221900.0</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.067170</td>\n",
              "      <td>0.003108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.097588</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.478261</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.893939</td>\n",
              "      <td>0.571498</td>\n",
              "      <td>0.217608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>538000.0</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.28125</td>\n",
              "      <td>0.172075</td>\n",
              "      <td>0.004072</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.206140</td>\n",
              "      <td>0.082988</td>\n",
              "      <td>0.443478</td>\n",
              "      <td>0.988089</td>\n",
              "      <td>0.626263</td>\n",
              "      <td>0.908959</td>\n",
              "      <td>0.166113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>180000.0</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.036226</td>\n",
              "      <td>0.005743</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.286957</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.936143</td>\n",
              "      <td>0.237542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>604000.0</td>\n",
              "      <td>0.121212</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>0.126038</td>\n",
              "      <td>0.002714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.188797</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.586939</td>\n",
              "      <td>0.104651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>510000.0</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.25000</td>\n",
              "      <td>0.104906</td>\n",
              "      <td>0.004579</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.152412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.368687</td>\n",
              "      <td>0.741354</td>\n",
              "      <td>0.393688</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      price  bedrooms  bathrooms  ...   zipcode       lat      long\n",
              "0  221900.0  0.090909    0.12500  ...  0.893939  0.571498  0.217608\n",
              "1  538000.0  0.090909    0.28125  ...  0.626263  0.908959  0.166113\n",
              "2  180000.0  0.060606    0.12500  ...  0.136364  0.936143  0.237542\n",
              "3  604000.0  0.121212    0.37500  ...  0.681818  0.586939  0.104651\n",
              "4  510000.0  0.090909    0.25000  ...  0.368687  0.741354  0.393688\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN6QhEuF4fTq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "7fa57aa5-b462-4b1c-ddf5-c64f1b4f702d"
      },
      "source": [
        "scaler_y = MinMaxScaler()\n",
        "base[['price']] = scaler_y.fit_transform(base[['price']])\n",
        "base.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.019266</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.067170</td>\n",
              "      <td>0.003108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.097588</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.478261</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.893939</td>\n",
              "      <td>0.571498</td>\n",
              "      <td>0.217608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.060721</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.28125</td>\n",
              "      <td>0.172075</td>\n",
              "      <td>0.004072</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.206140</td>\n",
              "      <td>0.082988</td>\n",
              "      <td>0.443478</td>\n",
              "      <td>0.988089</td>\n",
              "      <td>0.626263</td>\n",
              "      <td>0.908959</td>\n",
              "      <td>0.166113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.013770</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.036226</td>\n",
              "      <td>0.005743</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.286957</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.936143</td>\n",
              "      <td>0.237542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.069377</td>\n",
              "      <td>0.121212</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>0.126038</td>\n",
              "      <td>0.002714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.188797</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.586939</td>\n",
              "      <td>0.104651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.057049</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.25000</td>\n",
              "      <td>0.104906</td>\n",
              "      <td>0.004579</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.152412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.368687</td>\n",
              "      <td>0.741354</td>\n",
              "      <td>0.393688</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      price  bedrooms  bathrooms  ...   zipcode       lat      long\n",
              "0  0.019266  0.090909    0.12500  ...  0.893939  0.571498  0.217608\n",
              "1  0.060721  0.090909    0.28125  ...  0.626263  0.908959  0.166113\n",
              "2  0.013770  0.060606    0.12500  ...  0.136364  0.936143  0.237542\n",
              "3  0.069377  0.121212    0.37500  ...  0.681818  0.586939  0.104651\n",
              "4  0.057049  0.090909    0.25000  ...  0.368687  0.741354  0.393688\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WefOZ4OG406j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = base.drop('price', axis=1)\n",
        "y = base.price"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG3YUe7847KT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "93fd3807-e4b8-4bfe-8cf4-fcef89b10e10"
      },
      "source": [
        "x.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.067170</td>\n",
              "      <td>0.003108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.097588</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.478261</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.893939</td>\n",
              "      <td>0.571498</td>\n",
              "      <td>0.217608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.28125</td>\n",
              "      <td>0.172075</td>\n",
              "      <td>0.004072</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.206140</td>\n",
              "      <td>0.082988</td>\n",
              "      <td>0.443478</td>\n",
              "      <td>0.988089</td>\n",
              "      <td>0.626263</td>\n",
              "      <td>0.908959</td>\n",
              "      <td>0.166113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.036226</td>\n",
              "      <td>0.005743</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.286957</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.936143</td>\n",
              "      <td>0.237542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.121212</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>0.126038</td>\n",
              "      <td>0.002714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.188797</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.586939</td>\n",
              "      <td>0.104651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.25000</td>\n",
              "      <td>0.104906</td>\n",
              "      <td>0.004579</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.152412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.368687</td>\n",
              "      <td>0.741354</td>\n",
              "      <td>0.393688</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bedrooms  bathrooms  sqft_living  ...   zipcode       lat      long\n",
              "0  0.090909    0.12500     0.067170  ...  0.893939  0.571498  0.217608\n",
              "1  0.090909    0.28125     0.172075  ...  0.626263  0.908959  0.166113\n",
              "2  0.060606    0.12500     0.036226  ...  0.136364  0.936143  0.237542\n",
              "3  0.121212    0.37500     0.126038  ...  0.681818  0.586939  0.104651\n",
              "4  0.090909    0.25000     0.104906  ...  0.368687  0.741354  0.393688\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJWJH5zp5CWC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7d9f3ea7-b2d0-4b8c-8ff6-9faa4df45194"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.019266\n",
              "1    0.060721\n",
              "2    0.013770\n",
              "3    0.069377\n",
              "4    0.057049\n",
              "Name: price, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5WdMA7b5HlB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "8a13a104-ddee-481e-a29e-edcbea3d7d0e"
      },
      "source": [
        "previsors_columns = columns_used[1:17]\n",
        "previsors_columns"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bedrooms',\n",
              " 'bathrooms',\n",
              " 'sqft_living',\n",
              " 'sqft_lot',\n",
              " 'floors',\n",
              " 'waterfront',\n",
              " 'view',\n",
              " 'condition',\n",
              " 'grade',\n",
              " 'sqft_above',\n",
              " 'sqft_basement',\n",
              " 'yr_built',\n",
              " 'yr_renovated',\n",
              " 'zipcode',\n",
              " 'lat',\n",
              " 'long']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwgVYGZV5TNk",
        "colab_type": "text"
      },
      "source": [
        "## Tensorflow work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgDG48No5PC9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "910a2d8e-387f-4ef0-c488-123b6e88e69c"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5GOFWrl5a_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create feature columns\n",
        "columns = [tf.feature_column.numeric_column(key = c) for c in previsors_columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqY3GtjC5laD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtvxyGQg53ih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "97d60830-63a9-4a05-9aa2-a2794340c370"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15129, 16)\n",
            "(6484, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lPUGPYf546u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e4b1668-8390-494f-8778-2e0ee41ab1a9"
      },
      "source": [
        "function_training = tf.estimator.inputs.pandas_input_fn(\n",
        "    x= x_train, \n",
        "    y= y_train, \n",
        "    batch_size=32, \n",
        "    num_epochs=None, \n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "regresor = tf.estimator.DNNRegressor(hidden_units=[8, 8, 8], feature_columns= columns)\n",
        "regresor.train(input_fn=function_training, steps=20000)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp6jui21wi\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp6jui21wi', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp6jui21wi/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 1.0859911, step = 1\n",
            "INFO:tensorflow:global_step/sec: 339.184\n",
            "INFO:tensorflow:loss = 0.052555177, step = 101 (0.303 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.966\n",
            "INFO:tensorflow:loss = 0.058280587, step = 201 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 355.333\n",
            "INFO:tensorflow:loss = 0.024818435, step = 301 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 361.584\n",
            "INFO:tensorflow:loss = 0.045178838, step = 401 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 350.046\n",
            "INFO:tensorflow:loss = 0.020969369, step = 501 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.223\n",
            "INFO:tensorflow:loss = 0.016424004, step = 601 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 354.579\n",
            "INFO:tensorflow:loss = 0.008717788, step = 701 (0.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.131\n",
            "INFO:tensorflow:loss = 0.01700184, step = 801 (0.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 343.732\n",
            "INFO:tensorflow:loss = 0.016001806, step = 901 (0.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 329.673\n",
            "INFO:tensorflow:loss = 0.019379554, step = 1001 (0.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 345.549\n",
            "INFO:tensorflow:loss = 0.015742516, step = 1101 (0.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.569\n",
            "INFO:tensorflow:loss = 0.0066887904, step = 1201 (0.269 sec)\n",
            "INFO:tensorflow:global_step/sec: 360.714\n",
            "INFO:tensorflow:loss = 0.021276034, step = 1301 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 354.256\n",
            "INFO:tensorflow:loss = 0.020503629, step = 1401 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.134\n",
            "INFO:tensorflow:loss = 0.023747846, step = 1501 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.145\n",
            "INFO:tensorflow:loss = 0.05395609, step = 1601 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.219\n",
            "INFO:tensorflow:loss = 0.009054248, step = 1701 (0.272 sec)\n",
            "INFO:tensorflow:global_step/sec: 354.549\n",
            "INFO:tensorflow:loss = 0.0068591377, step = 1801 (0.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.799\n",
            "INFO:tensorflow:loss = 0.07746729, step = 1901 (0.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.552\n",
            "INFO:tensorflow:loss = 0.018449534, step = 2001 (0.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 349.654\n",
            "INFO:tensorflow:loss = 0.0077588893, step = 2101 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.789\n",
            "INFO:tensorflow:loss = 0.004375516, step = 2201 (0.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 347.717\n",
            "INFO:tensorflow:loss = 0.0041305562, step = 2301 (0.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 355.43\n",
            "INFO:tensorflow:loss = 0.019833338, step = 2401 (0.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 356.624\n",
            "INFO:tensorflow:loss = 0.007122866, step = 2501 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 348.966\n",
            "INFO:tensorflow:loss = 0.015186304, step = 2601 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 342.412\n",
            "INFO:tensorflow:loss = 0.008164713, step = 2701 (0.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 339.315\n",
            "INFO:tensorflow:loss = 0.010744888, step = 2801 (0.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 312.624\n",
            "INFO:tensorflow:loss = 0.01920553, step = 2901 (0.326 sec)\n",
            "INFO:tensorflow:global_step/sec: 320.4\n",
            "INFO:tensorflow:loss = 0.009952625, step = 3001 (0.309 sec)\n",
            "INFO:tensorflow:global_step/sec: 325.197\n",
            "INFO:tensorflow:loss = 0.021798192, step = 3101 (0.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 355.479\n",
            "INFO:tensorflow:loss = 0.016812218, step = 3201 (0.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.513\n",
            "INFO:tensorflow:loss = 0.0073999134, step = 3301 (0.292 sec)\n",
            "INFO:tensorflow:global_step/sec: 352.702\n",
            "INFO:tensorflow:loss = 0.03239296, step = 3401 (0.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 354.449\n",
            "INFO:tensorflow:loss = 0.021153694, step = 3501 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.478\n",
            "INFO:tensorflow:loss = 0.012154672, step = 3601 (0.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 354.911\n",
            "INFO:tensorflow:loss = 0.02236107, step = 3701 (0.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 345.347\n",
            "INFO:tensorflow:loss = 0.022406194, step = 3801 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.441\n",
            "INFO:tensorflow:loss = 0.016083868, step = 3901 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 341.067\n",
            "INFO:tensorflow:loss = 0.006791896, step = 4001 (0.291 sec)\n",
            "INFO:tensorflow:global_step/sec: 354.226\n",
            "INFO:tensorflow:loss = 0.01130447, step = 4101 (0.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.531\n",
            "INFO:tensorflow:loss = 0.006967978, step = 4201 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 352.655\n",
            "INFO:tensorflow:loss = 0.009016493, step = 4301 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 365.021\n",
            "INFO:tensorflow:loss = 0.016004773, step = 4401 (0.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 342.07\n",
            "INFO:tensorflow:loss = 0.008294385, step = 4501 (0.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.229\n",
            "INFO:tensorflow:loss = 0.010748233, step = 4601 (0.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 348.956\n",
            "INFO:tensorflow:loss = 0.011334607, step = 4701 (0.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 326.267\n",
            "INFO:tensorflow:loss = 0.008344564, step = 4801 (0.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 345.239\n",
            "INFO:tensorflow:loss = 0.0074193203, step = 4901 (0.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 349.799\n",
            "INFO:tensorflow:loss = 0.009400601, step = 5001 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 360.942\n",
            "INFO:tensorflow:loss = 0.024434568, step = 5101 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.565\n",
            "INFO:tensorflow:loss = 0.017180778, step = 5201 (0.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.067\n",
            "INFO:tensorflow:loss = 0.013494097, step = 5301 (0.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.644\n",
            "INFO:tensorflow:loss = 0.013690276, step = 5401 (0.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 352.223\n",
            "INFO:tensorflow:loss = 0.028495625, step = 5501 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 350.973\n",
            "INFO:tensorflow:loss = 0.005400335, step = 5601 (0.290 sec)\n",
            "INFO:tensorflow:global_step/sec: 361.792\n",
            "INFO:tensorflow:loss = 0.010512419, step = 5701 (0.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.839\n",
            "INFO:tensorflow:loss = 0.0035186494, step = 5801 (0.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 348.608\n",
            "INFO:tensorflow:loss = 0.014403166, step = 5901 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 348.849\n",
            "INFO:tensorflow:loss = 0.009303486, step = 6001 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 356.225\n",
            "INFO:tensorflow:loss = 0.0061752424, step = 6101 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.655\n",
            "INFO:tensorflow:loss = 0.006418896, step = 6201 (0.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 333.999\n",
            "INFO:tensorflow:loss = 0.010655936, step = 6301 (0.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 330.914\n",
            "INFO:tensorflow:loss = 0.036993682, step = 6401 (0.305 sec)\n",
            "INFO:tensorflow:global_step/sec: 311.103\n",
            "INFO:tensorflow:loss = 0.051536355, step = 6501 (0.322 sec)\n",
            "INFO:tensorflow:global_step/sec: 321.635\n",
            "INFO:tensorflow:loss = 0.005316739, step = 6601 (0.315 sec)\n",
            "INFO:tensorflow:global_step/sec: 358.028\n",
            "INFO:tensorflow:loss = 0.008993648, step = 6701 (0.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.828\n",
            "INFO:tensorflow:loss = 0.007531083, step = 6801 (0.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 352.092\n",
            "INFO:tensorflow:loss = 0.012186075, step = 6901 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.258\n",
            "INFO:tensorflow:loss = 0.011485532, step = 7001 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 355.973\n",
            "INFO:tensorflow:loss = 0.033224538, step = 7101 (0.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 356.106\n",
            "INFO:tensorflow:loss = 0.12174579, step = 7201 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 334.262\n",
            "INFO:tensorflow:loss = 0.008245707, step = 7301 (0.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 354.136\n",
            "INFO:tensorflow:loss = 0.011188527, step = 7401 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 336.089\n",
            "INFO:tensorflow:loss = 0.025276603, step = 7501 (0.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 344.256\n",
            "INFO:tensorflow:loss = 0.013868112, step = 7601 (0.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 337.597\n",
            "INFO:tensorflow:loss = 0.01538164, step = 7701 (0.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 320.994\n",
            "INFO:tensorflow:loss = 0.014444697, step = 7801 (0.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 328.42\n",
            "INFO:tensorflow:loss = 0.009775166, step = 7901 (0.316 sec)\n",
            "INFO:tensorflow:global_step/sec: 333.827\n",
            "INFO:tensorflow:loss = 0.015575947, step = 8001 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.092\n",
            "INFO:tensorflow:loss = 0.031028938, step = 8101 (0.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.729\n",
            "INFO:tensorflow:loss = 0.016310629, step = 8201 (0.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 345.459\n",
            "INFO:tensorflow:loss = 0.028562818, step = 8301 (0.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.459\n",
            "INFO:tensorflow:loss = 0.008112383, step = 8401 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 352.532\n",
            "INFO:tensorflow:loss = 0.011581093, step = 8501 (0.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 350.192\n",
            "INFO:tensorflow:loss = 0.029189795, step = 8601 (0.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.894\n",
            "INFO:tensorflow:loss = 0.01595423, step = 8701 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 358.41\n",
            "INFO:tensorflow:loss = 0.009008784, step = 8801 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 341.052\n",
            "INFO:tensorflow:loss = 0.008536924, step = 8901 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 358.198\n",
            "INFO:tensorflow:loss = 0.012588313, step = 9001 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 345.672\n",
            "INFO:tensorflow:loss = 0.0064201383, step = 9101 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 359.475\n",
            "INFO:tensorflow:loss = 0.028921312, step = 9201 (0.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.251\n",
            "INFO:tensorflow:loss = 0.007352003, step = 9301 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 344.925\n",
            "INFO:tensorflow:loss = 0.0124973245, step = 9401 (0.290 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.952\n",
            "INFO:tensorflow:loss = 0.010917213, step = 9501 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 355.304\n",
            "INFO:tensorflow:loss = 0.0376693, step = 9601 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 350.126\n",
            "INFO:tensorflow:loss = 0.022146972, step = 9701 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 339.331\n",
            "INFO:tensorflow:loss = 0.01781587, step = 9801 (0.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 325.624\n",
            "INFO:tensorflow:loss = 0.0077646924, step = 9901 (0.312 sec)\n",
            "INFO:tensorflow:global_step/sec: 313.84\n",
            "INFO:tensorflow:loss = 0.0059138974, step = 10001 (0.319 sec)\n",
            "INFO:tensorflow:global_step/sec: 343.676\n",
            "INFO:tensorflow:loss = 0.012396324, step = 10101 (0.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 339.025\n",
            "INFO:tensorflow:loss = 0.004905436, step = 10201 (0.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 350.65\n",
            "INFO:tensorflow:loss = 0.006493227, step = 10301 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.851\n",
            "INFO:tensorflow:loss = 0.03798258, step = 10401 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.182\n",
            "INFO:tensorflow:loss = 0.09003323, step = 10501 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 352.452\n",
            "INFO:tensorflow:loss = 0.005731743, step = 10601 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 331.779\n",
            "INFO:tensorflow:loss = 0.020183899, step = 10701 (0.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 338.655\n",
            "INFO:tensorflow:loss = 0.022177018, step = 10801 (0.290 sec)\n",
            "INFO:tensorflow:global_step/sec: 333.289\n",
            "INFO:tensorflow:loss = 0.004798466, step = 10901 (0.307 sec)\n",
            "INFO:tensorflow:global_step/sec: 326.008\n",
            "INFO:tensorflow:loss = 0.029767679, step = 11001 (0.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 334.949\n",
            "INFO:tensorflow:loss = 0.0118492, step = 11101 (0.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 315.15\n",
            "INFO:tensorflow:loss = 0.025334254, step = 11201 (0.317 sec)\n",
            "INFO:tensorflow:global_step/sec: 350.581\n",
            "INFO:tensorflow:loss = 0.012798833, step = 11301 (0.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 304.025\n",
            "INFO:tensorflow:loss = 0.013041132, step = 11401 (0.323 sec)\n",
            "INFO:tensorflow:global_step/sec: 321.71\n",
            "INFO:tensorflow:loss = 0.025434528, step = 11501 (0.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 348.937\n",
            "INFO:tensorflow:loss = 0.01917535, step = 11601 (0.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 337.485\n",
            "INFO:tensorflow:loss = 0.025177076, step = 11701 (0.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 340.257\n",
            "INFO:tensorflow:loss = 0.0062349886, step = 11801 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 339.91\n",
            "INFO:tensorflow:loss = 0.0135615505, step = 11901 (0.291 sec)\n",
            "INFO:tensorflow:global_step/sec: 313.161\n",
            "INFO:tensorflow:loss = 0.012563501, step = 12001 (0.327 sec)\n",
            "INFO:tensorflow:global_step/sec: 316.994\n",
            "INFO:tensorflow:loss = 0.0067414744, step = 12101 (0.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 361.685\n",
            "INFO:tensorflow:loss = 0.013127312, step = 12201 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 315.092\n",
            "INFO:tensorflow:loss = 0.013531111, step = 12301 (0.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 311.104\n",
            "INFO:tensorflow:loss = 0.018538188, step = 12401 (0.314 sec)\n",
            "INFO:tensorflow:global_step/sec: 343.478\n",
            "INFO:tensorflow:loss = 0.009085835, step = 12501 (0.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 322.177\n",
            "INFO:tensorflow:loss = 0.015547084, step = 12601 (0.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 296.294\n",
            "INFO:tensorflow:loss = 0.0065191262, step = 12701 (0.330 sec)\n",
            "INFO:tensorflow:global_step/sec: 306.922\n",
            "INFO:tensorflow:loss = 0.018998284, step = 12801 (0.336 sec)\n",
            "INFO:tensorflow:global_step/sec: 342.207\n",
            "INFO:tensorflow:loss = 0.022782767, step = 12901 (0.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 301.449\n",
            "INFO:tensorflow:loss = 0.013837393, step = 13001 (0.330 sec)\n",
            "INFO:tensorflow:global_step/sec: 317.035\n",
            "INFO:tensorflow:loss = 0.0102225505, step = 13101 (0.316 sec)\n",
            "INFO:tensorflow:global_step/sec: 327.787\n",
            "INFO:tensorflow:loss = 0.008502694, step = 13201 (0.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 330.131\n",
            "INFO:tensorflow:loss = 0.013102724, step = 13301 (0.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 338.932\n",
            "INFO:tensorflow:loss = 0.030812407, step = 13401 (0.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 316.403\n",
            "INFO:tensorflow:loss = 0.0073858537, step = 13501 (0.319 sec)\n",
            "INFO:tensorflow:global_step/sec: 308.55\n",
            "INFO:tensorflow:loss = 0.011573766, step = 13601 (0.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 320.525\n",
            "INFO:tensorflow:loss = 0.015822353, step = 13701 (0.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 343.859\n",
            "INFO:tensorflow:loss = 0.006068071, step = 13801 (0.291 sec)\n",
            "INFO:tensorflow:global_step/sec: 396.32\n",
            "INFO:tensorflow:loss = 0.019914296, step = 13901 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 311.295\n",
            "INFO:tensorflow:loss = 0.009388177, step = 14001 (0.322 sec)\n",
            "INFO:tensorflow:global_step/sec: 331.766\n",
            "INFO:tensorflow:loss = 0.03424736, step = 14101 (0.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 317.696\n",
            "INFO:tensorflow:loss = 0.0045418246, step = 14201 (0.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 349.575\n",
            "INFO:tensorflow:loss = 0.0055980133, step = 14301 (0.291 sec)\n",
            "INFO:tensorflow:global_step/sec: 325.179\n",
            "INFO:tensorflow:loss = 0.014537998, step = 14401 (0.314 sec)\n",
            "INFO:tensorflow:global_step/sec: 371.618\n",
            "INFO:tensorflow:loss = 0.006830573, step = 14501 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 354.45\n",
            "INFO:tensorflow:loss = 0.016879467, step = 14601 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 350.732\n",
            "INFO:tensorflow:loss = 0.015418194, step = 14701 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 359.184\n",
            "INFO:tensorflow:loss = 0.011126025, step = 14801 (0.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 356.551\n",
            "INFO:tensorflow:loss = 0.0074815075, step = 14901 (0.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 348.21\n",
            "INFO:tensorflow:loss = 0.014425099, step = 15001 (0.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 346.75\n",
            "INFO:tensorflow:loss = 0.0084511535, step = 15101 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 360.811\n",
            "INFO:tensorflow:loss = 0.014762622, step = 15201 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.804\n",
            "INFO:tensorflow:loss = 0.016378159, step = 15301 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 339.034\n",
            "INFO:tensorflow:loss = 0.009914946, step = 15401 (0.291 sec)\n",
            "INFO:tensorflow:global_step/sec: 347.434\n",
            "INFO:tensorflow:loss = 0.031107187, step = 15501 (0.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 342.669\n",
            "INFO:tensorflow:loss = 0.0037607676, step = 15601 (0.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 319.279\n",
            "INFO:tensorflow:loss = 0.00603473, step = 15701 (0.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 361.073\n",
            "INFO:tensorflow:loss = 0.006995247, step = 15801 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 343.509\n",
            "INFO:tensorflow:loss = 0.013923832, step = 15901 (0.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 328.611\n",
            "INFO:tensorflow:loss = 0.008149555, step = 16001 (0.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 344.965\n",
            "INFO:tensorflow:loss = 0.021976251, step = 16101 (0.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 320.902\n",
            "INFO:tensorflow:loss = 0.011886243, step = 16201 (0.314 sec)\n",
            "INFO:tensorflow:global_step/sec: 311.758\n",
            "INFO:tensorflow:loss = 0.010142255, step = 16301 (0.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 303.707\n",
            "INFO:tensorflow:loss = 0.0051537557, step = 16401 (0.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 331.183\n",
            "INFO:tensorflow:loss = 0.022062624, step = 16501 (0.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 333.653\n",
            "INFO:tensorflow:loss = 0.0088369865, step = 16601 (0.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 330.003\n",
            "INFO:tensorflow:loss = 0.005007305, step = 16701 (0.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 318.777\n",
            "INFO:tensorflow:loss = 0.013403737, step = 16801 (0.313 sec)\n",
            "INFO:tensorflow:global_step/sec: 348.168\n",
            "INFO:tensorflow:loss = 0.021292513, step = 16901 (0.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 340.942\n",
            "INFO:tensorflow:loss = 0.0160622, step = 17001 (0.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 335.758\n",
            "INFO:tensorflow:loss = 0.0059653916, step = 17101 (0.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 325.784\n",
            "INFO:tensorflow:loss = 0.0078002177, step = 17201 (0.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 337.206\n",
            "INFO:tensorflow:loss = 0.014529632, step = 17301 (0.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 330.127\n",
            "INFO:tensorflow:loss = 0.014788645, step = 17401 (0.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 341.88\n",
            "INFO:tensorflow:loss = 0.009574265, step = 17501 (0.292 sec)\n",
            "INFO:tensorflow:global_step/sec: 343.789\n",
            "INFO:tensorflow:loss = 0.008931232, step = 17601 (0.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 318.031\n",
            "INFO:tensorflow:loss = 0.014240337, step = 17701 (0.313 sec)\n",
            "INFO:tensorflow:global_step/sec: 325.029\n",
            "INFO:tensorflow:loss = 0.011691168, step = 17801 (0.309 sec)\n",
            "INFO:tensorflow:global_step/sec: 338.703\n",
            "INFO:tensorflow:loss = 0.026581813, step = 17901 (0.307 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.103\n",
            "INFO:tensorflow:loss = 0.010059462, step = 18001 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 341.648\n",
            "INFO:tensorflow:loss = 0.016463235, step = 18101 (0.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 354.767\n",
            "INFO:tensorflow:loss = 0.017286398, step = 18201 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.621\n",
            "INFO:tensorflow:loss = 0.009847188, step = 18301 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.049\n",
            "INFO:tensorflow:loss = 0.0065019624, step = 18401 (0.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 337.043\n",
            "INFO:tensorflow:loss = 0.020369027, step = 18501 (0.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.828\n",
            "INFO:tensorflow:loss = 0.007817827, step = 18601 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 346.996\n",
            "INFO:tensorflow:loss = 0.06994007, step = 18701 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 343.63\n",
            "INFO:tensorflow:loss = 0.008940061, step = 18801 (0.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 333.109\n",
            "INFO:tensorflow:loss = 0.016261186, step = 18901 (0.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 330.12\n",
            "INFO:tensorflow:loss = 0.0451312, step = 19001 (0.303 sec)\n",
            "INFO:tensorflow:global_step/sec: 336.471\n",
            "INFO:tensorflow:loss = 0.05940243, step = 19101 (0.291 sec)\n",
            "INFO:tensorflow:global_step/sec: 347.372\n",
            "INFO:tensorflow:loss = 0.012949368, step = 19201 (0.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 333.438\n",
            "INFO:tensorflow:loss = 0.01036725, step = 19301 (0.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 326.768\n",
            "INFO:tensorflow:loss = 0.011078795, step = 19401 (0.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 355.532\n",
            "INFO:tensorflow:loss = 0.008120226, step = 19501 (0.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.981\n",
            "INFO:tensorflow:loss = 0.015606086, step = 19601 (0.271 sec)\n",
            "INFO:tensorflow:global_step/sec: 364.25\n",
            "INFO:tensorflow:loss = 0.01846755, step = 19701 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 341.005\n",
            "INFO:tensorflow:loss = 0.0055031497, step = 19801 (0.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 341.849\n",
            "INFO:tensorflow:loss = 0.0062880493, step = 19901 (0.303 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 20000...\n",
            "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/tmp6jui21wi/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 20000...\n",
            "INFO:tensorflow:Loss for final step: 0.005361567.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressor at 0x7fa71afa5208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y5Aanh76-NK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "function_prevision = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_test,\n",
        "    y=y_test,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "previsions = regresor.predict(input_fn=function_prevision)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiGy6J7q8e0I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "431b3ea0-f26f-46a7-d6ab-8383e229b55c"
      },
      "source": [
        "values_previsions = []\n",
        "for p in regresor.predict(input_fn=function_prevision):\n",
        "  values_previsions.append(p['predictions'][0])\n",
        "\n",
        "values_previsions"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp6jui21wi/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.039641142,\n",
              " 0.05071774,\n",
              " 0.15472227,\n",
              " 0.023045102,\n",
              " 0.11493601,\n",
              " 0.06362107,\n",
              " 0.25885874,\n",
              " 0.05113387,\n",
              " 0.09764128,\n",
              " 0.023261847,\n",
              " 0.023045102,\n",
              " 0.08879538,\n",
              " 0.040493377,\n",
              " 0.05843804,\n",
              " 0.36516312,\n",
              " 0.031733148,\n",
              " 0.0928592,\n",
              " 0.023045102,\n",
              " 0.029611658,\n",
              " 0.03451477,\n",
              " 0.0885321,\n",
              " 0.042170994,\n",
              " 0.13275325,\n",
              " 0.08229592,\n",
              " 0.023045102,\n",
              " 0.04060061,\n",
              " 0.053990446,\n",
              " 0.05168091,\n",
              " 0.07897359,\n",
              " 0.06541555,\n",
              " 0.044740632,\n",
              " 0.06325298,\n",
              " 0.023045102,\n",
              " 0.11580361,\n",
              " 0.041177157,\n",
              " 0.052369237,\n",
              " 0.06466523,\n",
              " 0.023045102,\n",
              " 0.06364945,\n",
              " 0.082685,\n",
              " 0.05241561,\n",
              " 0.042877242,\n",
              " 0.030224584,\n",
              " 0.08294282,\n",
              " 0.065342925,\n",
              " 0.042718887,\n",
              " 0.023045102,\n",
              " 0.04715237,\n",
              " 0.03481391,\n",
              " 0.02380917,\n",
              " 0.04944237,\n",
              " 0.05965119,\n",
              " 0.032181017,\n",
              " 0.023045102,\n",
              " 0.07588688,\n",
              " 0.036575593,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.065213986,\n",
              " 0.059350193,\n",
              " 0.16358304,\n",
              " 0.023045102,\n",
              " 0.070339866,\n",
              " 0.053672757,\n",
              " 0.037538506,\n",
              " 0.059653863,\n",
              " 0.048115868,\n",
              " 0.045711093,\n",
              " 0.06304046,\n",
              " 0.051718585,\n",
              " 0.07096641,\n",
              " 0.10837874,\n",
              " 0.023045102,\n",
              " 0.07504839,\n",
              " 0.075373076,\n",
              " 0.024412863,\n",
              " 0.06705499,\n",
              " 0.26606146,\n",
              " 0.036852572,\n",
              " 0.085973896,\n",
              " 0.066492155,\n",
              " 0.07163056,\n",
              " 0.023045102,\n",
              " 0.075318106,\n",
              " 0.033671044,\n",
              " 0.102247566,\n",
              " 0.04932676,\n",
              " 0.05822122,\n",
              " 0.023045102,\n",
              " 0.029259356,\n",
              " 0.058222093,\n",
              " 0.024193162,\n",
              " 0.024753904,\n",
              " 0.04580682,\n",
              " 0.035450142,\n",
              " 0.04507058,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.061150394,\n",
              " 0.19639106,\n",
              " 0.11576628,\n",
              " 0.023045102,\n",
              " 0.14907114,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.030656446,\n",
              " 0.094066106,\n",
              " 0.037155423,\n",
              " 0.061586536,\n",
              " 0.040043246,\n",
              " 0.07239175,\n",
              " 0.10231166,\n",
              " 0.04677441,\n",
              " 0.048165508,\n",
              " 0.04353912,\n",
              " 0.023045102,\n",
              " 0.0599422,\n",
              " 0.08481953,\n",
              " 0.0814304,\n",
              " 0.061951607,\n",
              " 0.023365892,\n",
              " 0.04459292,\n",
              " 0.06433017,\n",
              " 0.023045102,\n",
              " 0.04428447,\n",
              " 0.023045102,\n",
              " 0.045436174,\n",
              " 0.051542133,\n",
              " 0.02924477,\n",
              " 0.030429047,\n",
              " 0.027417919,\n",
              " 0.040023137,\n",
              " 0.07207701,\n",
              " 0.09905877,\n",
              " 0.030179365,\n",
              " 0.04655633,\n",
              " 0.14096667,\n",
              " 0.054706432,\n",
              " 0.19286612,\n",
              " 0.07606949,\n",
              " 0.047001045,\n",
              " 0.12732811,\n",
              " 0.106344566,\n",
              " 0.035784744,\n",
              " 0.024835074,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.19735065,\n",
              " 0.046276614,\n",
              " 0.08774833,\n",
              " 0.023045102,\n",
              " 0.05331999,\n",
              " 0.0345491,\n",
              " 0.023045102,\n",
              " 0.08638731,\n",
              " 0.023045102,\n",
              " 0.04120972,\n",
              " 0.023236874,\n",
              " 0.032676987,\n",
              " 0.04470226,\n",
              " 0.023045102,\n",
              " 0.057479203,\n",
              " 0.025407486,\n",
              " 0.023045102,\n",
              " 0.07600664,\n",
              " 0.023045102,\n",
              " 0.058292985,\n",
              " 0.0531473,\n",
              " 0.038000736,\n",
              " 0.06431386,\n",
              " 0.1292247,\n",
              " 0.030359026,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.042782515,\n",
              " 0.069810644,\n",
              " 0.092349164,\n",
              " 0.04604947,\n",
              " 0.05585046,\n",
              " 0.2164887,\n",
              " 0.07327583,\n",
              " 0.023045102,\n",
              " 0.06461559,\n",
              " 0.06395257,\n",
              " 0.07114165,\n",
              " 0.054104548,\n",
              " 0.023045102,\n",
              " 0.118305355,\n",
              " 0.026817383,\n",
              " 0.049301315,\n",
              " 0.023045102,\n",
              " 0.047458027,\n",
              " 0.05517081,\n",
              " 0.062250033,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.023622224,\n",
              " 0.122740835,\n",
              " 0.039510395,\n",
              " 0.0587465,\n",
              " 0.04599426,\n",
              " 0.086792536,\n",
              " 0.047489017,\n",
              " 0.0598251,\n",
              " 0.23430255,\n",
              " 0.037516706,\n",
              " 0.102195054,\n",
              " 0.07264653,\n",
              " 0.026106197,\n",
              " 0.052391615,\n",
              " 0.023045102,\n",
              " 0.05267458,\n",
              " 0.023045102,\n",
              " 0.029414868,\n",
              " 0.12397345,\n",
              " 0.11179915,\n",
              " 0.02411578,\n",
              " 0.0963495,\n",
              " 0.054464765,\n",
              " 0.07124208,\n",
              " 0.039719015,\n",
              " 0.023045102,\n",
              " 0.06229312,\n",
              " 0.08258786,\n",
              " 0.08552654,\n",
              " 0.06766529,\n",
              " 0.08082624,\n",
              " 0.07644405,\n",
              " 0.023045102,\n",
              " 0.09788486,\n",
              " 0.023045102,\n",
              " 0.04230012,\n",
              " 0.06402569,\n",
              " 0.09438351,\n",
              " 0.023045102,\n",
              " 0.13109234,\n",
              " 0.07468536,\n",
              " 0.1718135,\n",
              " 0.05753769,\n",
              " 0.04064656,\n",
              " 0.06771292,\n",
              " 0.023892438,\n",
              " 0.023045102,\n",
              " 0.10972217,\n",
              " 0.11871257,\n",
              " 0.055796795,\n",
              " 0.12671544,\n",
              " 0.039135225,\n",
              " 0.051469795,\n",
              " 0.036990367,\n",
              " 0.046524372,\n",
              " 0.06526673,\n",
              " 0.023525422,\n",
              " 0.042684227,\n",
              " 0.058160454,\n",
              " 0.1002873,\n",
              " 0.023045102,\n",
              " 0.06167067,\n",
              " 0.052102003,\n",
              " 0.0287534,\n",
              " 0.05885581,\n",
              " 0.03334532,\n",
              " 0.028390862,\n",
              " 0.023045102,\n",
              " 0.06423164,\n",
              " 0.07040363,\n",
              " 0.060682707,\n",
              " 0.037997577,\n",
              " 0.023045102,\n",
              " 0.14953464,\n",
              " 0.094113834,\n",
              " 0.023045102,\n",
              " 0.034806915,\n",
              " 0.023045102,\n",
              " 0.5195728,\n",
              " 0.023045102,\n",
              " 0.03914211,\n",
              " 0.023045102,\n",
              " 0.05413739,\n",
              " 0.03704934,\n",
              " 0.023045102,\n",
              " 0.0955821,\n",
              " 0.05610794,\n",
              " 0.029851526,\n",
              " 0.057240456,\n",
              " 0.28900573,\n",
              " 0.09601591,\n",
              " 0.11111457,\n",
              " 0.023045102,\n",
              " 0.051385947,\n",
              " 0.023045102,\n",
              " 0.054534025,\n",
              " 0.030450676,\n",
              " 0.03586989,\n",
              " 0.11787952,\n",
              " 0.058299586,\n",
              " 0.038522296,\n",
              " 0.05249174,\n",
              " 0.036483895,\n",
              " 0.046882235,\n",
              " 0.033112057,\n",
              " 0.03470438,\n",
              " 0.03277164,\n",
              " 0.029460367,\n",
              " 0.043599784,\n",
              " 0.03879214,\n",
              " 0.023045102,\n",
              " 0.07709667,\n",
              " 0.07033444,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.029982833,\n",
              " 0.038696148,\n",
              " 0.031738527,\n",
              " 0.14988485,\n",
              " 0.025171582,\n",
              " 0.14295861,\n",
              " 0.023045102,\n",
              " 0.07799053,\n",
              " 0.062305428,\n",
              " 0.06441541,\n",
              " 0.09587304,\n",
              " 0.051315557,\n",
              " 0.03843435,\n",
              " 0.11671638,\n",
              " 0.05661443,\n",
              " 0.060233913,\n",
              " 0.06734667,\n",
              " 0.09388322,\n",
              " 0.09972298,\n",
              " 0.10919719,\n",
              " 0.03495691,\n",
              " 0.054311514,\n",
              " 0.056859337,\n",
              " 0.4179929,\n",
              " 0.03023871,\n",
              " 0.07216646,\n",
              " 0.023045102,\n",
              " 0.029706422,\n",
              " 0.040733427,\n",
              " 0.06934557,\n",
              " 0.043912392,\n",
              " 0.02350831,\n",
              " 0.056954905,\n",
              " 0.07829441,\n",
              " 0.10432874,\n",
              " 0.06506888,\n",
              " 0.06288992,\n",
              " 0.06532402,\n",
              " 0.061835274,\n",
              " 0.030151349,\n",
              " 0.023045102,\n",
              " 0.047394697,\n",
              " 0.049205363,\n",
              " 0.12935689,\n",
              " 0.023744483,\n",
              " 0.023045102,\n",
              " 0.079403445,\n",
              " 0.042371653,\n",
              " 0.073410146,\n",
              " 0.054381214,\n",
              " 0.036412537,\n",
              " 0.07010744,\n",
              " 0.14494024,\n",
              " 0.025585558,\n",
              " 0.16762194,\n",
              " 0.06644197,\n",
              " 0.023045102,\n",
              " 0.12574817,\n",
              " 0.051439162,\n",
              " 0.023045102,\n",
              " 0.09319835,\n",
              " 0.071807824,\n",
              " 0.059823923,\n",
              " 0.06490971,\n",
              " 0.03590157,\n",
              " 0.026848799,\n",
              " 0.037631847,\n",
              " 0.072698236,\n",
              " 0.05395811,\n",
              " 0.06713118,\n",
              " 0.058403865,\n",
              " 0.029384352,\n",
              " 0.025646232,\n",
              " 0.06656685,\n",
              " 0.062325433,\n",
              " 0.04239419,\n",
              " 0.03322661,\n",
              " 0.038487777,\n",
              " 0.023132645,\n",
              " 0.033020243,\n",
              " 0.025165014,\n",
              " 0.042043477,\n",
              " 0.04318963,\n",
              " 0.023045102,\n",
              " 0.043818954,\n",
              " 0.11852473,\n",
              " 0.06608197,\n",
              " 0.10206992,\n",
              " 0.072750784,\n",
              " 0.061229087,\n",
              " 0.07311466,\n",
              " 0.30024496,\n",
              " 0.06516802,\n",
              " 0.06844277,\n",
              " 0.055902034,\n",
              " 0.023045102,\n",
              " 0.10975525,\n",
              " 0.047081925,\n",
              " 0.1604268,\n",
              " 0.08418196,\n",
              " 0.060710654,\n",
              " 0.069277935,\n",
              " 0.04277215,\n",
              " 0.055015616,\n",
              " 0.07384002,\n",
              " 0.0320974,\n",
              " 0.062366992,\n",
              " 0.17575255,\n",
              " 0.033392284,\n",
              " 0.11461875,\n",
              " 0.048618637,\n",
              " 0.059711725,\n",
              " 0.054706454,\n",
              " 0.050550982,\n",
              " 0.023045102,\n",
              " 0.042689838,\n",
              " 0.057280228,\n",
              " 0.10420985,\n",
              " 0.09457288,\n",
              " 0.063138455,\n",
              " 0.048418913,\n",
              " 0.08557075,\n",
              " 0.1280941,\n",
              " 0.031778052,\n",
              " 0.023045102,\n",
              " 0.06765342,\n",
              " 0.050716672,\n",
              " 0.023045102,\n",
              " 0.057535216,\n",
              " 0.06805565,\n",
              " 0.08035817,\n",
              " 0.09522811,\n",
              " 0.023045102,\n",
              " 0.0536298,\n",
              " 0.054128885,\n",
              " 0.04792937,\n",
              " 0.044319693,\n",
              " 0.02713819,\n",
              " 0.023512503,\n",
              " 0.02751865,\n",
              " 0.023045102,\n",
              " 0.051185727,\n",
              " 0.13467655,\n",
              " 0.025363512,\n",
              " 0.10869452,\n",
              " 0.05132936,\n",
              " 0.05933684,\n",
              " 0.04303536,\n",
              " 0.05921135,\n",
              " 0.08391756,\n",
              " 0.04587208,\n",
              " 0.04760592,\n",
              " 0.06362533,\n",
              " 0.08065384,\n",
              " 0.04273162,\n",
              " 0.057049148,\n",
              " 0.09828991,\n",
              " 0.076423876,\n",
              " 0.08667408,\n",
              " 0.041172042,\n",
              " 0.101701185,\n",
              " 0.023045102,\n",
              " 0.11272805,\n",
              " 0.023045102,\n",
              " 0.039283246,\n",
              " 0.041772254,\n",
              " 0.058873147,\n",
              " 0.18413007,\n",
              " 0.13785979,\n",
              " 0.055370107,\n",
              " 0.023066996,\n",
              " 0.085258305,\n",
              " 0.08396005,\n",
              " 0.0473772,\n",
              " 0.04061015,\n",
              " 0.023045102,\n",
              " 0.10151791,\n",
              " 0.08644113,\n",
              " 0.023045102,\n",
              " 0.05719389,\n",
              " 0.06359025,\n",
              " 0.032896686,\n",
              " 0.025273787,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.05469618,\n",
              " 0.056956857,\n",
              " 0.06914887,\n",
              " 0.08700778,\n",
              " 0.056037597,\n",
              " 0.023045102,\n",
              " 0.102047764,\n",
              " 0.21903114,\n",
              " 0.080348074,\n",
              " 0.08804768,\n",
              " 0.023045102,\n",
              " 0.09623975,\n",
              " 0.061535425,\n",
              " 0.023045102,\n",
              " 0.052904297,\n",
              " 0.023045102,\n",
              " 0.026343249,\n",
              " 0.060136713,\n",
              " 0.100525744,\n",
              " 0.05684346,\n",
              " 0.054324783,\n",
              " 0.15235436,\n",
              " 0.05344547,\n",
              " 0.11423049,\n",
              " 0.05338637,\n",
              " 0.06376045,\n",
              " 0.023045102,\n",
              " 0.07391254,\n",
              " 0.023045102,\n",
              " 0.05484002,\n",
              " 0.04150104,\n",
              " 0.05778432,\n",
              " 0.023045102,\n",
              " 0.048052635,\n",
              " 0.023045102,\n",
              " 0.032146275,\n",
              " 0.041628957,\n",
              " 0.052737176,\n",
              " 0.03585259,\n",
              " 0.08563814,\n",
              " 0.06837065,\n",
              " 0.025983093,\n",
              " 0.053822175,\n",
              " 0.059378423,\n",
              " 0.03350003,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.072626315,\n",
              " 0.033954274,\n",
              " 0.048994157,\n",
              " 0.06680788,\n",
              " 0.073535055,\n",
              " 0.06926162,\n",
              " 0.054653898,\n",
              " 0.1708444,\n",
              " 0.22806945,\n",
              " 0.04894712,\n",
              " 0.07492445,\n",
              " 0.069880806,\n",
              " 0.023045102,\n",
              " 0.106695555,\n",
              " 0.05636829,\n",
              " 0.025435697,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.052853625,\n",
              " 0.24507654,\n",
              " 0.072893046,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.07259625,\n",
              " 0.04167994,\n",
              " 0.09770279,\n",
              " 0.026265807,\n",
              " 0.05957096,\n",
              " 0.05665478,\n",
              " 0.060889773,\n",
              " 0.023045102,\n",
              " 0.105085246,\n",
              " 0.034626316,\n",
              " 0.03815402,\n",
              " 0.05010169,\n",
              " 0.062344275,\n",
              " 0.052024048,\n",
              " 0.023045102,\n",
              " 0.054411717,\n",
              " 0.03730294,\n",
              " 0.122956425,\n",
              " 0.040539503,\n",
              " 0.092367545,\n",
              " 0.07676441,\n",
              " 0.042394474,\n",
              " 0.06725491,\n",
              " 0.10309223,\n",
              " 0.05214525,\n",
              " 0.042390406,\n",
              " 0.1719023,\n",
              " 0.081015855,\n",
              " 0.066767834,\n",
              " 0.055857874,\n",
              " 0.09000951,\n",
              " 0.044855684,\n",
              " 0.108168595,\n",
              " 0.023045102,\n",
              " 0.15133902,\n",
              " 0.044557564,\n",
              " 0.029481992,\n",
              " 0.040565006,\n",
              " 0.061306708,\n",
              " 0.0490993,\n",
              " 0.0329255,\n",
              " 0.023045102,\n",
              " 0.067344815,\n",
              " 0.07650439,\n",
              " 0.023045102,\n",
              " 0.06040649,\n",
              " 0.09084062,\n",
              " 0.048730515,\n",
              " 0.07564111,\n",
              " 0.039429504,\n",
              " 0.03950081,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.05692806,\n",
              " 0.06362056,\n",
              " 0.023045102,\n",
              " 0.103445806,\n",
              " 0.023045102,\n",
              " 0.16025402,\n",
              " 0.023045102,\n",
              " 0.11668851,\n",
              " 0.023045102,\n",
              " 0.029135937,\n",
              " 0.025122669,\n",
              " 0.16523272,\n",
              " 0.038690094,\n",
              " 0.033431247,\n",
              " 0.03410507,\n",
              " 0.030738676,\n",
              " 0.100680865,\n",
              " 0.079384014,\n",
              " 0.023045102,\n",
              " 0.056626864,\n",
              " 0.068146974,\n",
              " 0.023045102,\n",
              " 0.051419213,\n",
              " 0.056028813,\n",
              " 0.025072051,\n",
              " 0.023045102,\n",
              " 0.06319119,\n",
              " 0.05759877,\n",
              " 0.1382345,\n",
              " 0.07342275,\n",
              " 0.07044843,\n",
              " 0.09085264,\n",
              " 0.07435807,\n",
              " 0.086769275,\n",
              " 0.034663796,\n",
              " 0.023045102,\n",
              " 0.13167205,\n",
              " 0.08272715,\n",
              " 0.054838896,\n",
              " 0.0531364,\n",
              " 0.063294515,\n",
              " 0.13557373,\n",
              " 0.14225197,\n",
              " 0.043071844,\n",
              " 0.045723822,\n",
              " 0.097907,\n",
              " 0.05904504,\n",
              " 0.06027451,\n",
              " 0.098929524,\n",
              " 0.023045102,\n",
              " 0.047165684,\n",
              " 0.040595993,\n",
              " 0.037393402,\n",
              " 0.023045102,\n",
              " 0.06900482,\n",
              " 0.084503114,\n",
              " 0.037694465,\n",
              " 0.023045102,\n",
              " 0.049679436,\n",
              " 0.045932487,\n",
              " 0.0470385,\n",
              " 0.023045102,\n",
              " 0.055192217,\n",
              " 0.06097415,\n",
              " 0.0513982,\n",
              " 0.054254346,\n",
              " 0.050718427,\n",
              " 0.06389664,\n",
              " 0.04833945,\n",
              " 0.023045102,\n",
              " 0.05172766,\n",
              " 0.047812264,\n",
              " 0.06436776,\n",
              " 0.026124608,\n",
              " 0.031511467,\n",
              " 0.05445636,\n",
              " 0.024314089,\n",
              " 0.05157403,\n",
              " 0.06295247,\n",
              " 0.043510266,\n",
              " 0.03496611,\n",
              " 0.082020454,\n",
              " 0.11200123,\n",
              " 0.05579123,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.028258935,\n",
              " 0.055370405,\n",
              " 0.026344491,\n",
              " 0.19801214,\n",
              " 0.081921965,\n",
              " 0.05354821,\n",
              " 0.08437154,\n",
              " 0.0793392,\n",
              " 0.023045102,\n",
              " 0.12840256,\n",
              " 0.06943212,\n",
              " 0.06020642,\n",
              " 0.023045102,\n",
              " 0.097613305,\n",
              " 0.06642589,\n",
              " 0.07126501,\n",
              " 0.03726653,\n",
              " 0.15474728,\n",
              " 0.114905536,\n",
              " 0.12018695,\n",
              " 0.08508532,\n",
              " 0.08697213,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.058826663,\n",
              " 0.07403312,\n",
              " 0.03586925,\n",
              " 0.042095777,\n",
              " 0.060104452,\n",
              " 0.032932043,\n",
              " 0.05593984,\n",
              " 0.05875486,\n",
              " 0.034929827,\n",
              " 0.060006373,\n",
              " 0.05940102,\n",
              " 0.056891322,\n",
              " 0.039165787,\n",
              " 0.023045102,\n",
              " 0.033860747,\n",
              " 0.029985027,\n",
              " 0.035530433,\n",
              " 0.15767303,\n",
              " 0.08100856,\n",
              " 0.023045102,\n",
              " 0.06851314,\n",
              " 0.028494412,\n",
              " 0.06209542,\n",
              " 0.046693914,\n",
              " 0.023045102,\n",
              " 0.108049475,\n",
              " 0.08248355,\n",
              " 0.05947037,\n",
              " 0.10487248,\n",
              " 0.023045102,\n",
              " 0.02716911,\n",
              " 0.025723316,\n",
              " 0.10632701,\n",
              " 0.09872014,\n",
              " 0.053681888,\n",
              " 0.09857816,\n",
              " 0.06344771,\n",
              " 0.023045102,\n",
              " 0.02980341,\n",
              " 0.057869315,\n",
              " 0.023045102,\n",
              " 0.06772317,\n",
              " 0.068069324,\n",
              " 0.057290636,\n",
              " 0.023045102,\n",
              " 0.054573998,\n",
              " 0.0556641,\n",
              " 0.074122034,\n",
              " 0.07560739,\n",
              " 0.023045102,\n",
              " 0.10745528,\n",
              " 0.023045102,\n",
              " 0.05106692,\n",
              " 0.06480943,\n",
              " 0.11249725,\n",
              " 0.024719099,\n",
              " 0.072974406,\n",
              " 0.08748622,\n",
              " 0.043141954,\n",
              " 0.053702354,\n",
              " 0.038440574,\n",
              " 0.034890268,\n",
              " 0.023045102,\n",
              " 0.07709628,\n",
              " 0.120718345,\n",
              " 0.11058409,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.09045316,\n",
              " 0.06344147,\n",
              " 0.07292725,\n",
              " 0.13766827,\n",
              " 0.046713248,\n",
              " 0.05328565,\n",
              " 0.023045102,\n",
              " 0.09513704,\n",
              " 0.05313696,\n",
              " 0.03640804,\n",
              " 0.054960303,\n",
              " 0.034324825,\n",
              " 0.04160144,\n",
              " 0.0621187,\n",
              " 0.08070921,\n",
              " 0.13394995,\n",
              " 0.24633606,\n",
              " 0.10123043,\n",
              " 0.029575123,\n",
              " 0.069890305,\n",
              " 0.07668869,\n",
              " 0.05440428,\n",
              " 0.095571555,\n",
              " 0.06949929,\n",
              " 0.055039972,\n",
              " 0.11674561,\n",
              " 0.036610387,\n",
              " 0.02340481,\n",
              " 0.065257676,\n",
              " 0.042515844,\n",
              " 0.080221385,\n",
              " 0.08742034,\n",
              " 0.07748469,\n",
              " 0.041328255,\n",
              " 0.08063958,\n",
              " 0.023045102,\n",
              " 0.026696948,\n",
              " 0.023045102,\n",
              " 0.042486627,\n",
              " 0.04751785,\n",
              " 0.023045102,\n",
              " 0.050357766,\n",
              " 0.02511534,\n",
              " 0.030418715,\n",
              " 0.10034995,\n",
              " 0.023045102,\n",
              " 0.06439287,\n",
              " 0.023045102,\n",
              " 0.06273804,\n",
              " 0.023045102,\n",
              " 0.076647885,\n",
              " 0.041353405,\n",
              " 0.056785993,\n",
              " 0.09647573,\n",
              " 0.10131612,\n",
              " 0.12893246,\n",
              " 0.07518256,\n",
              " 0.024462413,\n",
              " 0.023045102,\n",
              " 0.060504504,\n",
              " 0.043608777,\n",
              " 0.06879847,\n",
              " 0.023045102,\n",
              " 0.062331103,\n",
              " 0.17854998,\n",
              " 0.07200768,\n",
              " 0.041415874,\n",
              " 0.05114355,\n",
              " 0.052150834,\n",
              " 0.060949102,\n",
              " 0.07089984,\n",
              " 0.0669169,\n",
              " 0.06262546,\n",
              " 0.060587466,\n",
              " 0.023045102,\n",
              " 0.06529335,\n",
              " 0.048313443,\n",
              " 0.04658666,\n",
              " 0.023045102,\n",
              " 0.06458326,\n",
              " 0.061794743,\n",
              " 0.1003926,\n",
              " 0.023045102,\n",
              " 0.109168895,\n",
              " 0.07387189,\n",
              " 0.053993687,\n",
              " 0.03057048,\n",
              " 0.031539172,\n",
              " 0.08605482,\n",
              " 0.03064479,\n",
              " 0.07500646,\n",
              " 0.041085448,\n",
              " 0.11389865,\n",
              " 0.046748184,\n",
              " 0.047620732,\n",
              " 0.049236372,\n",
              " 0.08581498,\n",
              " 0.038030125,\n",
              " 0.043462984,\n",
              " 0.058078885,\n",
              " 0.07409649,\n",
              " 0.03522421,\n",
              " 0.040655334,\n",
              " 0.06290602,\n",
              " 0.034354985,\n",
              " 0.09129598,\n",
              " 0.20161207,\n",
              " 0.041310545,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.106552586,\n",
              " 0.063857384,\n",
              " 0.058926575,\n",
              " 0.023045102,\n",
              " 0.025691096,\n",
              " 0.061452538,\n",
              " 0.023045102,\n",
              " 0.048282303,\n",
              " 0.023045102,\n",
              " 0.06020397,\n",
              " 0.04957112,\n",
              " 0.12876685,\n",
              " 0.05601769,\n",
              " 0.09323962,\n",
              " 0.033960097,\n",
              " 0.06912121,\n",
              " 0.094341084,\n",
              " 0.08060091,\n",
              " 0.025263967,\n",
              " 0.09260709,\n",
              " 0.046376795,\n",
              " 0.056875892,\n",
              " 0.025987836,\n",
              " 0.023045102,\n",
              " 0.07304601,\n",
              " 0.04047155,\n",
              " 0.048713136,\n",
              " 0.12801923,\n",
              " 0.06751472,\n",
              " 0.032167796,\n",
              " 0.082945436,\n",
              " 0.057195507,\n",
              " 0.04439739,\n",
              " 0.029675284,\n",
              " 0.028585546,\n",
              " 0.08816864,\n",
              " 0.0955708,\n",
              " 0.071904875,\n",
              " 0.023045102,\n",
              " 0.03706468,\n",
              " 0.09416404,\n",
              " 0.032089196,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.028136663,\n",
              " 0.056851514,\n",
              " 0.023045102,\n",
              " 0.051642478,\n",
              " 0.023045102,\n",
              " 0.056559704,\n",
              " 0.023045102,\n",
              " 0.023045102,\n",
              " 0.06360827,\n",
              " 0.054755688,\n",
              " 0.02339798,\n",
              " 0.036489557,\n",
              " 0.078965686,\n",
              " 0.05936476,\n",
              " 0.033597846,\n",
              " 0.06073294,\n",
              " 0.061664082,\n",
              " 0.025813865,\n",
              " 0.023045102,\n",
              " 0.09727152,\n",
              " 0.06426972,\n",
              " 0.023045102,\n",
              " 0.102978036,\n",
              " 0.07906393,\n",
              " 0.028150752,\n",
              " 0.059057772,\n",
              " 0.12394288,\n",
              " 0.06084936,\n",
              " 0.05417856,\n",
              " 0.023045102,\n",
              " 0.06612427,\n",
              " 0.044360638,\n",
              " 0.05065971,\n",
              " 0.07033771,\n",
              " 0.036582164,\n",
              " 0.023045102,\n",
              " 0.056143858,\n",
              " 0.049459547,\n",
              " 0.023045102,\n",
              " 0.087512046,\n",
              " 0.023045102,\n",
              " 0.051396683,\n",
              " 0.03834676,\n",
              " 0.049042515,\n",
              " 0.05258564,\n",
              " 0.027088627,\n",
              " 0.073712,\n",
              " 0.06939172,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SpRGFJ4800P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "75e9a191-15ba-463e-d7ae-c14a312199cf"
      },
      "source": [
        "import numpy as np \n",
        "values_previsions = np.asarray(values_previsions).reshape(-1, 1)\n",
        "values_previsions = scaler_y.inverse_transform(values_previsions)\n",
        "values_previsions"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.1934349e+19],\n",
              "       [2.6844851e+19],\n",
              "       [7.2952381e+19],\n",
              "       ...,\n",
              "       [1.4576954e+19],\n",
              "       [2.6620953e+19],\n",
              "       [4.8168078e+19]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mRQsdHn9NXr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "94414c85-4a36-4228-ff69-f7fc6d1222a0"
      },
      "source": [
        "y_test2 = y_test.values.reshape(-1, 1)\n",
        "y_test2 = scaler_y.inverse_transform(y_test2)\n",
        "y_test2"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 250000.],\n",
              "       [ 225000.],\n",
              "       [1408760.],\n",
              "       ...,\n",
              "       [ 227000.],\n",
              "       [ 605000.],\n",
              "       [ 795000.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGjQTrxU9vC_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1ce32fe-8bfb-4687-fb2a-f2c277c393bd"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "mae = mean_absolute_error(y_test2, values_previsions)\n",
        "mae"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.1984609284410556e+19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87FBJ1X7-LTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}