{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "census_dataset_nn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFdlBqfTUVBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "c11cebd3-6615-4e12-8d8c-63e892fe5cef"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/joberthrogers18/Machine-Learning-Training/master/Machine-Learning-Datascience/pre-processing/census.csv\"\n",
        "base = pd.read_csv(url)\n",
        "base.head()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>final-weight</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loos</th>\n",
              "      <th>hour-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age          workclass  final-weight  ... hour-per-week  native-country  income\n",
              "0   39          State-gov         77516  ...            40   United-States   <=50K\n",
              "1   50   Self-emp-not-inc         83311  ...            13   United-States   <=50K\n",
              "2   38            Private        215646  ...            40   United-States   <=50K\n",
              "3   53            Private        234721  ...            40   United-States   <=50K\n",
              "4   28            Private        338409  ...            40            Cuba   <=50K\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKMA_BCNUejU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01184ee1-028e-4b37-978f-50503435090b"
      },
      "source": [
        "base.income.unique()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' <=50K', ' >50K'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PahqjZiwX8Ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_enconder  = LabelEncoder()\n",
        "base.income = label_enconder.fit_transform(base.income)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLjSTJ-2eC7D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "95db0890-ff4b-461b-d529-56e6b61aba5d"
      },
      "source": [
        "base.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>final-weight</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loos</th>\n",
              "      <th>hour-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age          workclass  final-weight  ... hour-per-week  native-country income\n",
              "0   39          State-gov         77516  ...            40   United-States      0\n",
              "1   50   Self-emp-not-inc         83311  ...            13   United-States      0\n",
              "2   38            Private        215646  ...            40   United-States      0\n",
              "3   53            Private        234721  ...            40   United-States      0\n",
              "4   28            Private        338409  ...            40            Cuba      0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxDzdSxDemWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = base.drop('income', axis=1)\n",
        "y = base.income"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsBcEbFRe5dC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ7GcOhIfY-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iLMOlJ7hoOF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c3d78115-fd88-4d62-a17a-007e94b3c8da"
      },
      "source": [
        "base.workclass.unique()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' State-gov', ' Self-emp-not-inc', ' Private', ' Federal-gov',\n",
              "       ' Local-gov', ' ?', ' Self-emp-inc', ' Without-pay',\n",
              "       ' Never-worked'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaTplLPWgtgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "workclass = tf.feature_column.categorical_column_with_hash_bucket(key = 'workclass', hash_bucket_size= 100)\n",
        "education = tf.feature_column.categorical_column_with_hash_bucket(key = 'education', hash_bucket_size= 100)\n",
        "marital_status = tf.feature_column.categorical_column_with_hash_bucket(key = 'marital-status', hash_bucket_size=100)\n",
        "occupation = tf.feature_column.categorical_column_with_hash_bucket(key = 'occupation', hash_bucket_size= 100)\n",
        "relationship = tf.feature_column.categorical_column_with_hash_bucket(key = 'relationship', hash_bucket_size= 100)\n",
        "race = tf.feature_column.categorical_column_with_hash_bucket(key = 'race', hash_bucket_size= 100)\n",
        "country = tf.feature_column.categorical_column_with_hash_bucket(key = 'native-country', hash_bucket_size= 100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-6jPUSAic2r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e99f70d-e21b-4f08-9be6-a16a43879fda"
      },
      "source": [
        "base.sex.unique()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' Male', ' Female'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ7xy5iKi7V4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sex = tf.feature_column.categorical_column_with_vocabulary_list(key='sex', vocabulary_list=[' Male', ' Female'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOk00RC2jKLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "age = tf.feature_column.numeric_column(key='age')\n",
        "final_weight = tf.feature_column.numeric_column(key='final-weight')\n",
        "education_num = tf.feature_column.numeric_column(key='education-num')\n",
        "capital_gain = tf.feature_column.numeric_column(key='capital-gain')\n",
        "capital_loss = tf.feature_column.numeric_column(key='capital-loos')\n",
        "hour = tf.feature_column.numeric_column(key='hour-per-week')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a32QZUfakwpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = [ age, workclass, final_weight, education, education_num,\n",
        "            marital_status, occupation, relationship, race, sex,\n",
        "           capital_gain, capital_loss, hour, country\n",
        "           ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwcPWib1lIf_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "202b79ee-a0f5-4b9a-dc16-f47be8623c90"
      },
      "source": [
        "function_training = tf.estimator.inputs.pandas_input_fn(\n",
        "    x = x_train,\n",
        "    y = y_train,\n",
        "    batch_size=32, \n",
        "    num_epochs= None, \n",
        "    shuffle= True\n",
        ")\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    hidden_units=[8,8],\n",
        "    feature_columns=columns,\n",
        "    n_classes=2\n",
        ")\n",
        "\n",
        "classifier.train(input_fn= function_training)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpnpbjwtz6\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpnpbjwtz6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-b59c164849f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfunction_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1180\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1209\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m       estimator_spec = self._call_model_fn(features, labels, ModeKeys.TRAIN,\n\u001b[0;32m-> 1211\u001b[0;31m                                            self.config)\n\u001b[0m\u001b[1;32m   1212\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m    803\u001b[0m           \u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m           batch_norm=batch_norm)\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     super(DNNClassifier, self).__init__(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m_dnn_model_fn\u001b[0;34m(features, labels, mode, head, hidden_units, feature_columns, optimizer, activation_fn, dropout, input_layer_partitioner, config, use_tpu, batch_norm)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         batch_norm=batch_norm)\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     return _get_dnn_estimator_spec(use_tpu, head, features, labels, mode,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36mdnn_logit_fn\u001b[0;34m(features, mode)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mbatch_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         name='dnn')\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units, hidden_units, feature_columns, activation_fn, dropout, input_layer_partitioner, batch_norm, name, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_column_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feature_column_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m       self._input_layer = dense_features.DenseFeatures(\n\u001b[0;32m--> 177\u001b[0;31m           feature_columns=feature_columns, name='input_layer')\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m       self._input_layer = feature_column.InputLayer(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/dense_features.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, feature_columns, trainable, name, partitioner, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mexpected_column_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseColumn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, feature_columns, expected_column_type, trainable, name, partitioner, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;34m'You can wrap a categorical column with an '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             'embedding_column or indicator_column. Given: {}'.format(\n\u001b[0;32m--> 404\u001b[0;31m                 expected_column_type, column))\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Items of feature_columns must be a <class 'tensorflow.python.feature_column.feature_column_v2.DenseColumn'>. You can wrap a categorical column with an embedding_column or indicator_column. Given: HashedCategoricalColumn(key='education', hash_bucket_size=100, dtype=tf.string)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuRJFv-tlczy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedded_workclass = tf.feature_column.embedding_column(workclass, dimension=9)\n",
        "embedded_education = tf.feature_column.embedding_column(education, dimension=len(base.education.unique()))\n",
        "embedded_marital_status = tf.feature_column.embedding_column(marital_status, dimension=len(base['marital-status'].unique()))\n",
        "embedded_occupation = tf.feature_column.embedding_column(occupation, dimension=len(base.occupation.unique()))\n",
        "embedded_relationship = tf.feature_column.embedding_column(relationship, dimension=len(base.relationship.unique()))\n",
        "embedded_race = tf.feature_column.embedding_column(race, dimension=len(base.race.unique()))\n",
        "embedded_native_country = tf.feature_column.embedding_column(native_country, dimension=len(base['native-country'].unique()))\n",
        "embedded_country = tf.feature_column.embedding_column(country, dimension=len(base['native-country'].unique()))\n",
        "embedded_sex = tf.feature_column.embedding_column(sex, dimension=len(base.sex.unique()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bE1AuQWo21W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns_rna = [ age, embedded_workclass, final_weight, embedded_education, education_num,\n",
        "            embedded_marital_status, embedded_occupation, embedded_relationship, embedded_race, embedded_sex,\n",
        "           capital_gain, capital_loss, hour, embedded_country\n",
        "           ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zc75QwUrMHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63c1c1fd-0637-4c4b-f00c-59939200eb7b"
      },
      "source": [
        "function_training = tf.estimator.inputs.pandas_input_fn(\n",
        "    x = x_train,\n",
        "    y = y_train,\n",
        "    batch_size=32, \n",
        "    num_epochs= None, \n",
        "    shuffle= True\n",
        ")\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    hidden_units=[8,8],\n",
        "    feature_columns=columns_rna,\n",
        "    n_classes=2\n",
        ")\n",
        "\n",
        "classifier.train(input_fn= function_training, steps = 10000)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpvt3zw05l\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpvt3zw05l', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/adagrad.py:77: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py:906: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpvt3zw05l/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 842772.5, step = 1\n",
            "INFO:tensorflow:global_step/sec: 214.79\n",
            "INFO:tensorflow:loss = 4590.473, step = 101 (0.468 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 146 vs previous value: 146. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 287.727\n",
            "INFO:tensorflow:loss = 3961.9556, step = 201 (0.347 sec)\n",
            "INFO:tensorflow:global_step/sec: 323.764\n",
            "INFO:tensorflow:loss = 799.7793, step = 301 (0.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 310.871\n",
            "INFO:tensorflow:loss = 4539.333, step = 401 (0.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 284.783\n",
            "INFO:tensorflow:loss = 843.8327, step = 501 (0.357 sec)\n",
            "INFO:tensorflow:global_step/sec: 303.306\n",
            "INFO:tensorflow:loss = 746.758, step = 601 (0.327 sec)\n",
            "INFO:tensorflow:global_step/sec: 297.649\n",
            "INFO:tensorflow:loss = 877.11804, step = 701 (0.333 sec)\n",
            "INFO:tensorflow:global_step/sec: 304.147\n",
            "INFO:tensorflow:loss = 365.6516, step = 801 (0.332 sec)\n",
            "INFO:tensorflow:global_step/sec: 316.894\n",
            "INFO:tensorflow:loss = 247.03967, step = 901 (0.313 sec)\n",
            "INFO:tensorflow:global_step/sec: 319.567\n",
            "INFO:tensorflow:loss = 857.31213, step = 1001 (0.312 sec)\n",
            "INFO:tensorflow:global_step/sec: 313.25\n",
            "INFO:tensorflow:loss = 206.59087, step = 1101 (0.319 sec)\n",
            "INFO:tensorflow:global_step/sec: 313.362\n",
            "INFO:tensorflow:loss = 73.16678, step = 1201 (0.325 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1263 vs previous value: 1263. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 310.017\n",
            "INFO:tensorflow:loss = 115.29959, step = 1301 (0.315 sec)\n",
            "INFO:tensorflow:global_step/sec: 306.712\n",
            "INFO:tensorflow:loss = 273.7838, step = 1401 (0.330 sec)\n",
            "INFO:tensorflow:global_step/sec: 296.62\n",
            "INFO:tensorflow:loss = 93.24504, step = 1501 (0.335 sec)\n",
            "INFO:tensorflow:global_step/sec: 311.487\n",
            "INFO:tensorflow:loss = 186.81192, step = 1601 (0.321 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1644 vs previous value: 1644. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 296.392\n",
            "INFO:tensorflow:loss = 330.1801, step = 1701 (0.339 sec)\n",
            "INFO:tensorflow:global_step/sec: 311.116\n",
            "INFO:tensorflow:loss = 734.619, step = 1801 (0.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 318.133\n",
            "INFO:tensorflow:loss = 147.4651, step = 1901 (0.315 sec)\n",
            "INFO:tensorflow:global_step/sec: 312.966\n",
            "INFO:tensorflow:loss = 219.18362, step = 2001 (0.318 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2019 vs previous value: 2019. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 294.028\n",
            "INFO:tensorflow:loss = 21.011444, step = 2101 (0.341 sec)\n",
            "INFO:tensorflow:global_step/sec: 314.131\n",
            "INFO:tensorflow:loss = 128.67119, step = 2201 (0.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 308.616\n",
            "INFO:tensorflow:loss = 145.92021, step = 2301 (0.323 sec)\n",
            "INFO:tensorflow:global_step/sec: 303.425\n",
            "INFO:tensorflow:loss = 70.208496, step = 2401 (0.331 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2439 vs previous value: 2439. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 297.102\n",
            "INFO:tensorflow:loss = 163.25595, step = 2501 (0.343 sec)\n",
            "INFO:tensorflow:global_step/sec: 310.903\n",
            "INFO:tensorflow:loss = 24.548134, step = 2601 (0.314 sec)\n",
            "INFO:tensorflow:global_step/sec: 308.31\n",
            "INFO:tensorflow:loss = 26.559158, step = 2701 (0.328 sec)\n",
            "INFO:tensorflow:global_step/sec: 304.654\n",
            "INFO:tensorflow:loss = 29.658794, step = 2801 (0.330 sec)\n",
            "INFO:tensorflow:global_step/sec: 311.547\n",
            "INFO:tensorflow:loss = 267.86023, step = 2901 (0.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 297.306\n",
            "INFO:tensorflow:loss = 24.315388, step = 3001 (0.340 sec)\n",
            "INFO:tensorflow:global_step/sec: 310.417\n",
            "INFO:tensorflow:loss = 45.750336, step = 3101 (0.319 sec)\n",
            "INFO:tensorflow:global_step/sec: 311.07\n",
            "INFO:tensorflow:loss = 11.600761, step = 3201 (0.328 sec)\n",
            "INFO:tensorflow:global_step/sec: 307.017\n",
            "INFO:tensorflow:loss = 44.710075, step = 3301 (0.322 sec)\n",
            "INFO:tensorflow:global_step/sec: 302.525\n",
            "INFO:tensorflow:loss = 64.73297, step = 3401 (0.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 317.15\n",
            "INFO:tensorflow:loss = 21.631845, step = 3501 (0.313 sec)\n",
            "INFO:tensorflow:global_step/sec: 311.531\n",
            "INFO:tensorflow:loss = 186.2987, step = 3601 (0.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 290.376\n",
            "INFO:tensorflow:loss = 64.63663, step = 3701 (0.343 sec)\n",
            "INFO:tensorflow:global_step/sec: 308.977\n",
            "INFO:tensorflow:loss = 155.48367, step = 3801 (0.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 304.134\n",
            "INFO:tensorflow:loss = 78.877304, step = 3901 (0.325 sec)\n",
            "INFO:tensorflow:global_step/sec: 318.208\n",
            "INFO:tensorflow:loss = 14.753028, step = 4001 (0.315 sec)\n",
            "INFO:tensorflow:global_step/sec: 316.466\n",
            "INFO:tensorflow:loss = 255.07072, step = 4101 (0.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 311.417\n",
            "INFO:tensorflow:loss = 52.923553, step = 4201 (0.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 309.975\n",
            "INFO:tensorflow:loss = 303.62753, step = 4301 (0.322 sec)\n",
            "INFO:tensorflow:global_step/sec: 291.729\n",
            "INFO:tensorflow:loss = 22.802029, step = 4401 (0.344 sec)\n",
            "INFO:tensorflow:global_step/sec: 315.053\n",
            "INFO:tensorflow:loss = 16.926533, step = 4501 (0.319 sec)\n",
            "INFO:tensorflow:global_step/sec: 314.792\n",
            "INFO:tensorflow:loss = 24.27629, step = 4601 (0.319 sec)\n",
            "INFO:tensorflow:global_step/sec: 314.777\n",
            "INFO:tensorflow:loss = 43.19599, step = 4701 (0.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 306.315\n",
            "INFO:tensorflow:loss = 69.64982, step = 4801 (0.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 306.696\n",
            "INFO:tensorflow:loss = 40.956516, step = 4901 (0.331 sec)\n",
            "INFO:tensorflow:global_step/sec: 295.781\n",
            "INFO:tensorflow:loss = 56.682266, step = 5001 (0.340 sec)\n",
            "INFO:tensorflow:global_step/sec: 302.942\n",
            "INFO:tensorflow:loss = 49.74416, step = 5101 (0.326 sec)\n",
            "INFO:tensorflow:global_step/sec: 311.461\n",
            "INFO:tensorflow:loss = 105.58348, step = 5201 (0.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 317.854\n",
            "INFO:tensorflow:loss = 10.462837, step = 5301 (0.316 sec)\n",
            "INFO:tensorflow:global_step/sec: 308.455\n",
            "INFO:tensorflow:loss = 39.453682, step = 5401 (0.322 sec)\n",
            "INFO:tensorflow:global_step/sec: 308.499\n",
            "INFO:tensorflow:loss = 12.427921, step = 5501 (0.325 sec)\n",
            "INFO:tensorflow:global_step/sec: 307.649\n",
            "INFO:tensorflow:loss = 17.336527, step = 5601 (0.325 sec)\n",
            "INFO:tensorflow:global_step/sec: 314.243\n",
            "INFO:tensorflow:loss = 10.085089, step = 5701 (0.324 sec)\n",
            "INFO:tensorflow:global_step/sec: 299.989\n",
            "INFO:tensorflow:loss = 8.705404, step = 5801 (0.331 sec)\n",
            "INFO:tensorflow:global_step/sec: 295.322\n",
            "INFO:tensorflow:loss = 32.31809, step = 5901 (0.335 sec)\n",
            "INFO:tensorflow:global_step/sec: 309.2\n",
            "INFO:tensorflow:loss = 25.23995, step = 6001 (0.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 301.674\n",
            "INFO:tensorflow:loss = 10.893588, step = 6101 (0.327 sec)\n",
            "INFO:tensorflow:global_step/sec: 307.931\n",
            "INFO:tensorflow:loss = 60.03105, step = 6201 (0.325 sec)\n",
            "INFO:tensorflow:global_step/sec: 306.435\n",
            "INFO:tensorflow:loss = 107.61815, step = 6301 (0.326 sec)\n",
            "INFO:tensorflow:global_step/sec: 313.491\n",
            "INFO:tensorflow:loss = 28.86832, step = 6401 (0.323 sec)\n",
            "INFO:tensorflow:global_step/sec: 311.624\n",
            "INFO:tensorflow:loss = 74.47213, step = 6501 (0.317 sec)\n",
            "INFO:tensorflow:global_step/sec: 304.287\n",
            "INFO:tensorflow:loss = 19.285904, step = 6601 (0.331 sec)\n",
            "INFO:tensorflow:global_step/sec: 309.458\n",
            "INFO:tensorflow:loss = 31.749195, step = 6701 (0.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 308.729\n",
            "INFO:tensorflow:loss = 65.000084, step = 6801 (0.328 sec)\n",
            "INFO:tensorflow:global_step/sec: 300.475\n",
            "INFO:tensorflow:loss = 42.658993, step = 6901 (0.332 sec)\n",
            "INFO:tensorflow:global_step/sec: 281.399\n",
            "INFO:tensorflow:loss = 68.372986, step = 7001 (0.353 sec)\n",
            "INFO:tensorflow:global_step/sec: 320.545\n",
            "INFO:tensorflow:loss = 16.514702, step = 7101 (0.312 sec)\n",
            "INFO:tensorflow:global_step/sec: 312.445\n",
            "INFO:tensorflow:loss = 18.10603, step = 7201 (0.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 298.428\n",
            "INFO:tensorflow:loss = 41.638752, step = 7301 (0.335 sec)\n",
            "INFO:tensorflow:global_step/sec: 315.014\n",
            "INFO:tensorflow:loss = 26.510849, step = 7401 (0.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 316.018\n",
            "INFO:tensorflow:loss = 18.336874, step = 7501 (0.316 sec)\n",
            "INFO:tensorflow:global_step/sec: 300.444\n",
            "INFO:tensorflow:loss = 17.66093, step = 7601 (0.336 sec)\n",
            "INFO:tensorflow:global_step/sec: 312.483\n",
            "INFO:tensorflow:loss = 37.072186, step = 7701 (0.316 sec)\n",
            "INFO:tensorflow:global_step/sec: 315.318\n",
            "INFO:tensorflow:loss = 55.08617, step = 7801 (0.317 sec)\n",
            "INFO:tensorflow:global_step/sec: 312.651\n",
            "INFO:tensorflow:loss = 51.760345, step = 7901 (0.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 315.473\n",
            "INFO:tensorflow:loss = 11.39942, step = 8001 (0.315 sec)\n",
            "INFO:tensorflow:global_step/sec: 307.592\n",
            "INFO:tensorflow:loss = 37.300087, step = 8101 (0.325 sec)\n",
            "INFO:tensorflow:global_step/sec: 322.704\n",
            "INFO:tensorflow:loss = 19.73844, step = 8201 (0.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 306.846\n",
            "INFO:tensorflow:loss = 13.539734, step = 8301 (0.327 sec)\n",
            "INFO:tensorflow:global_step/sec: 307.275\n",
            "INFO:tensorflow:loss = 13.531437, step = 8401 (0.330 sec)\n",
            "INFO:tensorflow:global_step/sec: 319.812\n",
            "INFO:tensorflow:loss = 42.03945, step = 8501 (0.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 305.831\n",
            "INFO:tensorflow:loss = 20.845404, step = 8601 (0.326 sec)\n",
            "INFO:tensorflow:global_step/sec: 303.283\n",
            "INFO:tensorflow:loss = 40.98838, step = 8701 (0.330 sec)\n",
            "INFO:tensorflow:global_step/sec: 311.545\n",
            "INFO:tensorflow:loss = 19.488445, step = 8801 (0.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 299.744\n",
            "INFO:tensorflow:loss = 15.553423, step = 8901 (0.338 sec)\n",
            "INFO:tensorflow:global_step/sec: 304.22\n",
            "INFO:tensorflow:loss = 5.5730743, step = 9001 (0.325 sec)\n",
            "INFO:tensorflow:global_step/sec: 312.178\n",
            "INFO:tensorflow:loss = 8.052937, step = 9101 (0.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 302.135\n",
            "INFO:tensorflow:loss = 18.023457, step = 9201 (0.333 sec)\n",
            "INFO:tensorflow:global_step/sec: 312.944\n",
            "INFO:tensorflow:loss = 14.293535, step = 9301 (0.327 sec)\n",
            "INFO:tensorflow:global_step/sec: 300.894\n",
            "INFO:tensorflow:loss = 24.955763, step = 9401 (0.323 sec)\n",
            "INFO:tensorflow:global_step/sec: 300.857\n",
            "INFO:tensorflow:loss = 24.195852, step = 9501 (0.333 sec)\n",
            "INFO:tensorflow:global_step/sec: 310.782\n",
            "INFO:tensorflow:loss = 30.208885, step = 9601 (0.326 sec)\n",
            "INFO:tensorflow:global_step/sec: 312.195\n",
            "INFO:tensorflow:loss = 19.482147, step = 9701 (0.322 sec)\n",
            "INFO:tensorflow:global_step/sec: 306.368\n",
            "INFO:tensorflow:loss = 49.85016, step = 9801 (0.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 310.831\n",
            "INFO:tensorflow:loss = 20.01286, step = 9901 (0.325 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10000...\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmpvt3zw05l/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10000...\n",
            "INFO:tensorflow:Loss for final step: 15.373391.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x7fec866ca320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFvV2J7Gr0JF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "function_test = tf.estimator.inputs.pandas_input_fn(x = x_test, y= y_test, batch_size=32,\n",
        "                                                    num_epochs=1, shuffle=False\n",
        "                                                   )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVJ8EAbgso2F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "e7a77bd7-ece8-41e1-ed3d-2a2e13260e40"
      },
      "source": [
        "classifier.evaluate(input_fn=function_test)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/head.py:642: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-04-28T02:54:52Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpvt3zw05l/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 1.54080s\n",
            "INFO:tensorflow:Finished evaluation at 2020-04-28-02:54:54\n",
            "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.8153342, accuracy_baseline = 0.75975025, auc = 0.8276316, auc_precision_recall = 0.6754141, average_loss = 0.7147395, global_step = 10000, label/mean = 0.24024977, loss = 22.817942, precision = 0.83979976, prediction/mean = 0.09939257, recall = 0.2858969\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/tmpvt3zw05l/model.ckpt-10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8153342,\n",
              " 'accuracy_baseline': 0.75975025,\n",
              " 'auc': 0.8276316,\n",
              " 'auc_precision_recall': 0.6754141,\n",
              " 'average_loss': 0.7147395,\n",
              " 'global_step': 10000,\n",
              " 'label/mean': 0.24024977,\n",
              " 'loss': 22.817942,\n",
              " 'precision': 0.83979976,\n",
              " 'prediction/mean': 0.09939257,\n",
              " 'recall': 0.2858969}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQCdJ3Sbs6AI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}